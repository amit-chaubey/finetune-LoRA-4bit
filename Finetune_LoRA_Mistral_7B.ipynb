{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idirxoOTNiQr"
   },
   "source": [
    "#Requirements\n",
    "##1. What Problem are we solving - Fine tuning a model on LORA.\n",
    "##2. Frame a AI Solution.\n",
    "##3. Create Evaluation Metric\n",
    "##4. Prepare dataset\n",
    "##5. Train the model\n",
    "##6. Evaluate the model\n",
    "##7. Deploy the model in public and gather human feedback\n",
    "##8. Reiterate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZH7NU89NNXwe"
   },
   "source": [
    "##install important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbNoT1dLL1Ut"
   },
   "outputs": [],
   "source": [
    "!pip install datasets bitsandbytes trl transformers peft huggingface-hub accelerate safetensors pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lnl979bzLvMn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbMuMVA5Py51"
   },
   "source": [
    "##check if bf16 is provided else use float 16\n",
    "###float32 > bf16 > fp16\n",
    "###float32 is computational expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ekg8tF0TLvPO"
   },
   "outputs": [],
   "source": [
    "supported = torch.cuda.is_bf16_supported(including_emulation = False)\n",
    "dtype_compute = torch.bfloat16 if supported else torch.float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGAZLa5aRr-C"
   },
   "source": [
    "##Check BitsAndBytes parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFyFNJ88R0Aa",
    "outputId": "e2228865-7311-49d9-def2-29cf98884d61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BitsAndBytesConfig {\n",
       "  \"_load_in_4bit\": false,\n",
       "  \"_load_in_8bit\": false,\n",
       "  \"bnb_4bit_compute_dtype\": \"float32\",\n",
       "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "  \"bnb_4bit_quant_type\": \"fp4\",\n",
       "  \"bnb_4bit_use_double_quant\": false,\n",
       "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "  \"llm_int8_has_fp16_weight\": false,\n",
       "  \"llm_int8_skip_modules\": null,\n",
       "  \"llm_int8_threshold\": 6.0,\n",
       "  \"load_in_4bit\": false,\n",
       "  \"load_in_8bit\": false,\n",
       "  \"quant_method\": \"bitsandbytes\"\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig()\n",
    "bnb_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3FXOfrNQPYg"
   },
   "source": [
    "##Load Bitsandbytes config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6-WTtZKNLvUL"
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bng_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = dtype_compute,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbfhiTmgQsu0"
   },
   "source": [
    "##Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "cb718c11e5704140ae044a752b0e2774",
      "4407897626e7474aa099d3231d2ccb7f",
      "2b1a3a9166c940a09369c2f1c166fffe",
      "215053e1aa9c4833922063baa18a9da4",
      "a67f8af41da541ceabbe58ee2c1c3a27",
      "14a9c9e313c1409bbe2fbf471df35d0f",
      "ea9070eaf1e0446c9286fccedcc6f3f6",
      "d3ff5c0d8e9a403db57235cc7c261f21",
      "e0dd38d95afc4b1387ecc26d72a86e21",
      "8f2be49de7c947ebb94f79af85ae688b",
      "d0612ce86760416892f6f142b1f71182",
      "133d710199584e3cae1e4570b6e405b1",
      "c8120aec60164de49da8fb998269de45",
      "613137c52f86425e8c40b61659e71d52",
      "daf86d4d4763477197be3b998ca8ffc1",
      "60a68fe879bb4c2092887ad755fda0f9",
      "9b16e58d79df4ee193545ce7bda6d418",
      "56ddfde75c2e40a68b72f2488a849852",
      "3abfa5f194d24747b2d618295a364de1",
      "2d39ad9bdf994c909c74d17b419e739b",
      "31d9c836138647ccbc550529259a9c45",
      "03c357a9f00a48db93232bf32015a0e5",
      "d45530c006474fb7b0ee575b66f313e8",
      "cedfce9c5c834483a338ae833abbd871",
      "f6315593866c491b95de589070ac24dd",
      "23add68807c34af5870a4c5bbc38485e",
      "bb0b42113eca4e549700250af7b41328",
      "5a0ea0b774a449bd8ff3ec438eefc5e0",
      "aba131399d7b4477a38f0dc40a97793e",
      "0a9ae351f6614ffbba544706b4ec5b38",
      "73a1ac648ea141c79e4f9043381c96f5",
      "6d1746dc7a564825a0ea7f8710739bc6",
      "cb081ccdc4a249ac833ed6ead7278002",
      "cbb71e312d244774a20ec4f5686de891",
      "ac63dcc642a444a786555673739b8108",
      "335e326f8afc468bb9fdab7f132465f0",
      "5eae531daae24d56abf00bd8bd701b61",
      "6bd7f702191140c8b8becf7299da2947",
      "5b409c0927e54036ad5fb70dbd21e00e",
      "904329bf68b54594b710393f344935c5",
      "1cd936f15c5b49b18fce449750819da6",
      "2fe08a091a51464486a3f2683bcb1e4f",
      "d4b222b525404ac8b90f90a91432a3ec",
      "ad38ada9aade4bbfb643222a8c81a024",
      "d239a1035ce440d1abced179abe76820",
      "e93493aaaf874e3887b13a1b8e49e005",
      "b9d94324214847019d056339d5e25034",
      "b8abbaa625e74cfbac86d1d593ec10d3",
      "6624961648634daf9ca8fadc779280ae",
      "3ac7aef504f648df9856da1e31236fd2",
      "7ef41f2e45ea415395eafc3652cda7db",
      "159ff5af29fe4b2d82a608aeed3a8fbd",
      "56a2b5ba2cd642219559f0904cf3d0f9",
      "83bbbc94cc4040e1a42afd53e86f223c",
      "795a0524827c4c2fbc22d58e43d11737",
      "7803da1af64d4b38a818565e229cfc6c",
      "c8548b59441d49bab8ff9a82d72d5080",
      "fe2bc46e4f004b298032e40968bb30d4",
      "93df43302eb044d8b36e32e6daab5835",
      "8f657398950a4690aa5a875d46610252",
      "fa9139dc6e0d4363af77b1baeb7260a3",
      "72697c95047840c9adcc1d631fafdc31",
      "42cf10409c4943228cafa3c57af5a98f",
      "c27dc35b526943dfb99e04d8d6b0043a",
      "cdf199b98b7f4178a9303ddfdbca070c",
      "425f1e941a38422e81649dc8243cd1f2",
      "aaf34465c3f94136a27a5e819fc47c1a",
      "2add4d77b01d447c96d32bfe4690dc17",
      "a1e4beb5e23541ee9198114fba0513ba",
      "6933ca3b5e684115a72639b4d0528061",
      "78554b4738f54ed7874a2a09ce6db7b4",
      "17b9dbdf536849d6aa40a9297eff6589",
      "32a5f316e20b4a759bc56b07b9dd8d6e",
      "04ce334ce1a94db8b2ba3a0bb2615be3",
      "f86aa30d41314107805026e2d4108c05",
      "9011ff39fe4f4afc93f6ef995dc95b26",
      "d6922e492ae040158703540706c72560",
      "de705600e08b4a5c96128f5a4aab9e6f",
      "514062d2bd29479098a8d1578097bdf7",
      "2a4e2bfd225a461788b5c1e47597ebf3",
      "738f861f41e04337a396e468943f2630",
      "02eb83e2857943e2b64a2798d8211b94",
      "1cc0507c99844a6593ae1eba2b41b8b8",
      "4e5cf391b7484c83b86c0587480efca2",
      "8a46f1d6c983437285e98a8b95c763b5",
      "7ac61ec372584158804649ad4a109c68",
      "485289ff81074bf69b6245baec0fa775",
      "dce3951b294d479b9f80a6923d18451f"
     ]
    },
    "id": "_VqaKRsMLvXd",
    "outputId": "56245582-3076-41f4-a912-5f306d68c3d6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb718c11e5704140ae044a752b0e2774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133d710199584e3cae1e4570b6e405b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45530c006474fb7b0ee575b66f313e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb71e312d244774a20ec4f5686de891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d239a1035ce440d1abced179abe76820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7803da1af64d4b38a818565e229cfc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf34465c3f94136a27a5e819fc47c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de705600e08b4a5c96128f5a4aab9e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\", #meta/llama-2-7b-chat-hf\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = \"cuda:0\",\n",
    "    torch_dtype = dtype_compute,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cJx-QjjRJhM"
   },
   "source": [
    "##Add Layer of Lora config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bquNXJ7EOaPe"
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABfvuEejSUO1"
   },
   "source": [
    "#PerpareDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b6c5ddb05b444e4d8d58562e3a81deef",
      "13522a5b0d12463f9cc6b7425f47c48f",
      "c76c8eee589b4fca9b7eb00184c2e859",
      "2758c42d29474d7a9a739f670c912a95",
      "84bc6ba4f57d40bf97668e1238388803",
      "ed06d26a0b3140dda2ea4b33a0a7c902",
      "4dfdecf7ec40449bb1b6927ea36528b2",
      "56cc55988a80471f9dd901c2fef6ef03",
      "b07dbd4f84674c8a9b15fd437f3698ba",
      "16738d72d85d43dc908ce79bb48cacb6",
      "02d0899808d84c88831d7683c29821f9",
      "07b0b0f76cc642bf965d385b5ec42cd8",
      "cada357f701841cd999bf9251e83bc04",
      "2bd4998330554d90a19984e5a45ca7f4",
      "c14a473ad9e34806b61964c5dae9133b",
      "729eb032bb034dde8bdbff3a2eec6b1f",
      "468af344e9c849ad8febf124f3174864",
      "2bfe421be4004e5e905fe74913b67bee",
      "5545d4e0317b43f8a91daa8431bd5ffa",
      "fc22b33f9f7e43e3a435dd949892cb15",
      "9cc8c50dfe00443b86b1a8a1a1f2f150",
      "f7998526bdc0445b855ecfbda3249dcb",
      "374086991beb41e9ad4b359bcd50e294",
      "82ed6d0cdc4c4d0abb8342fb58f53479",
      "695fc6727df646e08f64d12cf8d48bbe",
      "9578f12b5aba4176933ae51d5bf14da9",
      "4cda77616fd34636aa84723252716e9a",
      "fff4ee5493114bbe91ee56eb0443ceb5",
      "691a18ffb84a49eda86fdbdb7a7e565b",
      "b35f433322a24bcbaa4c2b793647df5a",
      "737f58d40c624b139a4e672ed84c48af",
      "6263256746e94c26b057516edfcaea1b",
      "e5878747e3ab4aef8ed006c2fd260335",
      "c6cf9e8c093f4ebca139d7a52cbf8517",
      "9da1b2465ae04ce792ee296dbe3f6c1c",
      "25087f1d90ad4c778cfd6ab9c539bc4f",
      "c62a37200c3f468ab04471f35daa05cc",
      "a1ada1d890a1408e8a511b8406b7cf0d",
      "e0d2d073c3224997903107a011a01a2f",
      "6d430fcb8d28446aa6b31d3563421411",
      "fcb3a1f88fc3454ab51da111e0b2fce4",
      "c096b191fcb848059695e1b82570e206",
      "b730640cf88642e4b82e0e7d7aec087c",
      "222f1f1acecb4705b68aea3faf000eb8"
     ]
    },
    "id": "1k-lS-DTSX4w",
    "outputId": "8b336792-8cc3-47ce-dce8-708416d53513"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c5ddb05b444e4d8d58562e3a81deef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b0b0f76cc642bf965d385b5ec42cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374086991beb41e9ad4b359bcd50e294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cf9e8c093f4ebca139d7a52cbf8517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{%- if messages[0][\"role\"] == \"system\" %}\n",
      "    {%- set system_message = messages[0][\"content\"] %}\n",
      "    {%- set loop_messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set loop_messages = messages %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}\n",
      "\n",
      "{#- This block checks for alternating user/assistant messages, skipping tool calling messages #}\n",
      "{%- set ns = namespace() %}\n",
      "{%- set ns.index = 0 %}\n",
      "{%- for message in loop_messages %}\n",
      "    {%- if not (message.role == \"tool\" or message.role == \"tool_results\" or (message.tool_calls is defined and message.tool_calls is not none)) %}\n",
      "        {%- if (message[\"role\"] == \"user\") != (ns.index % 2 == 0) %}\n",
      "            {{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
      "        {%- endif %}\n",
      "        {%- set ns.index = ns.index + 1 %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "\n",
      "{{- bos_token }}\n",
      "{%- for message in loop_messages %}\n",
      "    {%- if message[\"role\"] == \"user\" %}\n",
      "        {%- if tools is not none and (message == user_messages[-1]) %}\n",
      "            {{- \"[AVAILABLE_TOOLS] [\" }}\n",
      "            {%- for tool in tools %}\n",
      "                {%- set tool = tool.function %}\n",
      "                {{- '{\"type\": \"function\", \"function\": {' }}\n",
      "                {%- for key, val in tool.items() if key != \"return\" %}\n",
      "                    {%- if val is string %}\n",
      "                        {{- '\"' + key + '\": \"' + val + '\"' }}\n",
      "                    {%- else %}\n",
      "                        {{- '\"' + key + '\": ' + val|tojson }}\n",
      "                    {%- endif %}\n",
      "                    {%- if not loop.last %}\n",
      "                        {{- \", \" }}\n",
      "                    {%- endif %}\n",
      "                {%- endfor %}\n",
      "                {{- \"}}\" }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- else %}\n",
      "                    {{- \"]\" }}\n",
      "                {%- endif %}\n",
      "            {%- endfor %}\n",
      "            {{- \"[/AVAILABLE_TOOLS]\" }}\n",
      "            {%- endif %}\n",
      "        {%- if loop.last and system_message is defined %}\n",
      "            {{- \"[INST] \" + system_message + \"\\n\\n\" + message[\"content\"] + \"[/INST]\" }}\n",
      "        {%- else %}\n",
      "            {{- \"[INST] \" + message[\"content\"] + \"[/INST]\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.tool_calls is defined and message.tool_calls is not none %}\n",
      "        {{- \"[TOOL_CALLS] [\" }}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- set out = tool_call.function|tojson %}\n",
      "            {{- out[:-1] }}\n",
      "            {%- if not tool_call.id is defined or tool_call.id|length != 9 %}\n",
      "                {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
      "            {%- endif %}\n",
      "            {{- ', \"id\": \"' + tool_call.id + '\"}' }}\n",
      "            {%- if not loop.last %}\n",
      "                {{- \", \" }}\n",
      "            {%- else %}\n",
      "                {{- \"]\" + eos_token }}\n",
      "            {%- endif %}\n",
      "        {%- endfor %}\n",
      "    {%- elif message[\"role\"] == \"assistant\" %}\n",
      "        {{- \" \" + message[\"content\"]|trim + eos_token}}\n",
      "    {%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}\n",
      "        {%- if message.content is defined and message.content.content is defined %}\n",
      "            {%- set content = message.content.content %}\n",
      "        {%- else %}\n",
      "            {%- set content = message.content %}\n",
      "        {%- endif %}\n",
      "        {{- '[TOOL_RESULTS] {\"content\": ' + content|string + \", \" }}\n",
      "        {%- if not message.tool_call_id is defined or message.tool_call_id|length != 9 %}\n",
      "            {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
      "        {%- endif %}\n",
      "        {{- '\"call_id\": \"' + message.tool_call_id + '\"}[/TOOL_RESULTS]' }}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repo = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo)\n",
    "print(tokenizer.chat_template)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
