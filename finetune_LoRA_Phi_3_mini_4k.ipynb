{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "sQHHSSqt-Jl4",
    "outputId": "956e17c7-dda1-4c42-c6bf-5a51f39372fd"
   },
   "outputs": [],
   "source": [
    "!pip install datasets bitsandbytes trl huggingface-hub accelerate safetensors pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xaaffU0cCSWL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "13896a3dcc9a455991e1a4c0d7176a14",
      "b3d2c1abe0d04b58adf52d08f74a2dc5",
      "5194e10dbe1e47c8b57f5b560521bb5e",
      "8d7fce6eb08d40e6b9b820776bcce9fb",
      "3690e2df291e4d94af5db2bf7ad8f9cb",
      "393034a5c6c24f2981ff630ded073dde",
      "e66cdda7526e4c7fb70de66087b70b02",
      "f878d07b104a43f09b9e7b5332719c7d",
      "35c07860255d4e67b50fa408bdff6164",
      "7027d139f4194fb1aef0df7de6b47e0c",
      "661d3929dcac44f3a238364d43a932bd",
      "b28b6b9edb8642f8b54d438cb982d817",
      "8333d134eb834a3a81748e265132fedc",
      "d759b6d5f5fa46cb8e2e071d4e457a16",
      "62a99c82f862424d88f02d795bdc3eb0",
      "10894f9e7b364daca6bf706a40bb92e1",
      "8d3788afa56344f2914417a4d7429f41",
      "0f57f7b2148940539f745ff4bce78e27",
      "284fbc1d10ba4271824ba5394e4caff8",
      "151e89f9f76e4d87bad87948bef14acc",
      "eb56511a9b6b4193867a7d2811410eeb",
      "fbf89a869eaf4ac383665ce1c87111b4",
      "b6f066dd6a2b42a69fc3add37e090069",
      "0b5ba7be613a4aaba1904a372839d787",
      "4e344b8bd3ac4399bfb59c14e5df5e26",
      "359ed933382445fc9c5a9e564ef092be",
      "025c8dd797254b068fa685a057d1ce58",
      "3a4974c39fac4eee953835943c13ff83",
      "2c379512f6d04033b849d85f307e1b0c",
      "9c6861e8eedf48149ab6fab5a9737c80",
      "fbe360dd0ccf4eebbede0e51051bc4b3",
      "9b49240465ee4efda2e6d41948c1f376",
      "ba90debcf5d343b68264b0adf7297aef",
      "5caa06fe725a44f29c5b7f7e513e65b7",
      "01705b0d9112467c8379703df8b85079",
      "5dc577ac174a48c692c06e9f5519594a",
      "0064c21546e54c769f27a72b74f672bb",
      "0bf599a4496c44a6b8d5f8ba14fb2da5",
      "6ba3fe05385b4ea0b5ca14d7703f3545",
      "ee4df16d7ecf4975a38127bd7cc89e61",
      "eb3913b00de54289a1c03412e1ec2513",
      "4b41f8b57302481aa3bc64a208885a16",
      "0a7d57fb7da44012b215a55a32d1271c",
      "81dfa8ea208544388a462a1ccfdc19c6",
      "18be633290fc4c4e9664095efcdebdbb",
      "c27b0fb46fc643b5901e55bc025270b1",
      "697dfe72907a4615835aeaf1264ea378",
      "0ee176388f6c44249decb4d7dd16fdda",
      "ef797995f3db4024aa343b2a877561ad",
      "c91a451ae4de4a67aea9c318f7f437b4",
      "9af23966d4894c73bc583ec2ae82c923",
      "b2972d6300ba4dca9b434ef683c56f99",
      "66f47d40b59549138ff8d7afdf59a3b5",
      "17a9538a1f5240ec9217139ceb60c466",
      "f54b272d74bb45489fd25fb4cb30e716",
      "fe4599e4108140a3af1d3c93f85125fd",
      "24995964b67b4e41ac16788f1800f4a1",
      "f676d41343b44598aa6a1ffffdde93de",
      "2a1a4539e4834667a46f16ecebe6218c",
      "b07a1670ad07451282967f8b905ab485",
      "844f476d66a5491eb48bf5691772fa9b",
      "cb76e5950aac4ccc86ee698d83fbc4c8",
      "427acbef829a4c989b0300d99874564b",
      "9b286dc1392d4356b1a957977b1b187f",
      "1da0d44ec9c24da6ab19edd2ea6ef153",
      "9f086bdfd41041a69762370003269ff9",
      "b4341b476ea54f039e6e87bc6fd96d77",
      "b1fdac0310a54fddbb43219a480e075f",
      "6ccda40b26bb4d34b1f351576ae27b39",
      "0936997a74504e4b9192fc23d3c50452",
      "9ecade278ec14d69a072cd8665529865",
      "9994b2d25aa045988f770bec44adaafe",
      "982574b6dc804aa8b99b38bcc6378ae3",
      "1a3a00981e834668b42e3d00cc112aee",
      "d8e0c01397194d3589542121684bd778",
      "2e5f4791d39646f8b4775248e208e10b",
      "c31f2eb6cb6e43a6b9b27cabca3bd8ad"
     ]
    },
    "id": "XB_JtzX0DH1m",
    "outputId": "f10be114-3b38-462e-b398-29322df14b90"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13896a3dcc9a455991e1a4c0d7176a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28b6b9edb8642f8b54d438cb982d817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f066dd6a2b42a69fc3add37e090069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5caa06fe725a44f29c5b7f7e513e65b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18be633290fc4c4e9664095efcdebdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4599e4108140a3af1d3c93f85125fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4341b476ea54f039e6e87bc6fd96d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.float32,\n",
    "    bnb_4bit_use_double_quant= True\n",
    "    )\n",
    "repo = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(repo, quantization_config= bnb_config, device_map= \"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404,
     "referenced_widgets": [
      "6f328f1e805449ee8aa63282df93d482",
      "0c85b3f702004440a421c4f67a4ca237",
      "df9a74c2acc14a40b8cfe8bed7009bd7",
      "db49e3d01e1741c8bc55e57c42c0f24a",
      "8842adb0d57f493caaf42a17ba27e596",
      "65ca5dd5294c4308b10e0e1efb2fdc2b",
      "ea4b49ff735f4055be8c24fb2ccdd8e6",
      "7ee8c51ea6f746859d0ee258b21535d8",
      "1e6faca447434d00b29b78b73bb21e78",
      "295563ece6a94e758d20f942d76b600f",
      "4631897f39994eac86da61a10d233f1c",
      "ceb7e7d942434603baf5561c64ed8c1a",
      "a8d7da6743de42098ea1511a02b14e5a",
      "b42ee9b551064407a6505fe22e22f306",
      "e8ef9017892c49cda1fb81c9bc8068f6",
      "51083ac33e0f4ee7a1b35df7b35e1798",
      "bed5aa7765714923ab7dde7b8fd16bc4",
      "bcb079167a1949c3ac5fda9208077e35",
      "35dc7f78cbee4057ab6a97889c1e435d",
      "8a2f8eee538547c8b7e673c558b35c91",
      "2b29a2f2c0b34629b8af0d0191356950",
      "7528a71900424a8abe2ff229904677b5",
      "94343f5f80f8432c93500b52ce54f8c6",
      "05289a93b07a4d00bbc61e578aec735a",
      "e26a2d11ac8649f994c008d1bd488a03",
      "c20aab3015554670a31593464e938967",
      "e16e66546aff472ab4b3a38a54e51b64",
      "07c5b304ae9243828910c0dac5b5b931",
      "f124826ed3d04989bf2f44f9a4eef2fd",
      "ecb428438801443b8043ce570c0bd6f9",
      "ca05fc0029fa4242825b60e36575dba8",
      "469dd301fea54976acd39acb61bd8936",
      "c955ab4a17144281a4802c0e703effc0",
      "b3b332d5c4be489d859e3c89f5cff884",
      "ca67df6d67504506bdf6b118660e93c8",
      "a11928eb8bce431d94125f8d6a8dc63e",
      "17f30154fc7149bcb08a92e2481e0619",
      "f25ee0daa95741b8be2e39764df5d1cb",
      "90b2e233cc9b48e28de1f0e3ab04bfcc",
      "d28e1f702d81488280db9557c5a40e77",
      "384fc791dcb34587bf5d77b85e8f954f",
      "dc6027e3fa0c4fa4b3779a546c79109f",
      "19645b8be7a74569a6eb9105a0ba0a43",
      "25c478b133d54bb4b96e939f77d38007",
      "e05be2313a29496eb32170d2212d43df",
      "a18127c577a94795ac0c344e5093894e",
      "74e43ee482394ba68d78efd9fe30e5f1",
      "0f26f375995544a2821f0ad42d77949a",
      "7c761aefc78d46beaee567f44442a38c",
      "ecbdc09eb9cd46779dcebc11cb906e42",
      "26f5dfe7e3574cbbbdf5efd9f97fe92e",
      "551fc560c13c43f8b2fae90e92183f79",
      "475f1cc8e0514e56abaed9a063a1ca5c",
      "77a080b7f0bd49e6b1ce6c4b55f4315f",
      "78dc21361ebf47d7a424d39db807a115",
      "3f8050e3d35e41f689b3f688f04d7eac",
      "af8669fbefb6424aa25c3646c853c07f",
      "0f93c93d47b14402887bb730f6619979",
      "8fab82060d294880b3e8ddbc558029df",
      "b9afe560182c4d94831d0c352d35520b",
      "de75e6c0cb1647588d05a43d35102090",
      "fc49a7824b11474aa423b31edcd7002e",
      "372bd5a1e55943dab9344f67f3f48509",
      "26b6fe5a13ec4626b8ea2aed8f7d911f",
      "61d75957d8ee4c3eb93037c62db5e184",
      "ad6ad18a6ebe4b99ab9428f69d253e8c",
      "a21df4cf8f86460191339087d5375382",
      "699d273a8937453e8dab709c8cd9f9c8",
      "32ea5a1170d94f63a8965f9295099722",
      "baa503b94fe44159b530a0d70d25dca4",
      "8492ee04cc604642ab6fb1f227798a58",
      "62993273bacc4981bb839a812e3c8cae",
      "17f987b6ab744c918eb9b80bdf22d2ab",
      "92a0ca0d7bdd49e1a6290d74e9e184bb",
      "682edcc5b3b44b16a8752cfcccdaeb0f",
      "03aef82a4f284668ad97c25a5b096753",
      "ad86887d4f46422898c88c20acbefa07"
     ]
    },
    "collapsed": true,
    "id": "dnqd-dgmFvKf",
    "outputId": "d4ec5425-62a8-4a4b-bc7d-28e7b7054874"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f328f1e805449ee8aa63282df93d482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb7e7d942434603baf5561c64ed8c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94343f5f80f8432c93500b52ce54f8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b332d5c4be489d859e3c89f5cff884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05be2313a29496eb32170d2212d43df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8050e3d35e41f689b3f688f04d7eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21df4cf8f86460191339087d5375382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# torch.random.manual_seed(0)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "#     device_map=\"cuda\",\n",
    "#     torch_dtype=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
    "# ]\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# generation_args = {\n",
    "#     \"max_new_tokens\": 500,\n",
    "#     \"return_full_text\": False,\n",
    "#     \"temperature\": 0.0,\n",
    "#     \"do_sample\": False,\n",
    "# }\n",
    "\n",
    "# output = pipe(messages, **generation_args)\n",
    "# print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee3M9pnjEUaW",
    "outputId": "b4fd98f9-04f3-4d87-c64e-9074aa615e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2104.1310424804688\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRZA6aC4HXk4",
    "outputId": "098f4ab9-34b4-4e24-e0c4-e461989faba9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3ForCausalLM(\n",
       "  (model): Phi3Model(\n",
       "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x Phi3DecoderLayer(\n",
       "        (self_attn): Phi3Attention(\n",
       "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "        )\n",
       "        (mlp): Phi3MLP(\n",
       "          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "          (activation_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): Phi3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPoMdAY4JDbP",
    "outputId": "a0c4f9d9-618e-4c6a-cbcf-f60807f2decf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): PeftModelForCausalLM(\n",
       "      (base_model): LoraModel(\n",
       "        (model): PeftModelForCausalLM(\n",
       "          (base_model): LoraModel(\n",
       "            (model): PeftModelForCausalLM(\n",
       "              (base_model): LoraModel(\n",
       "                (model): PeftModelForCausalLM(\n",
       "                  (base_model): LoraModel(\n",
       "                    (model): Phi3ForCausalLM(\n",
       "                      (model): Phi3Model(\n",
       "                        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "                        (layers): ModuleList(\n",
       "                          (0-31): 32 x Phi3DecoderLayer(\n",
       "                            (self_attn): Phi3Attention(\n",
       "                              (o_proj): lora.Linear4bit(\n",
       "                                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                                (lora_dropout): ModuleDict(\n",
       "                                  (default): Dropout(p=0.05, inplace=False)\n",
       "                                )\n",
       "                                (lora_A): ModuleDict(\n",
       "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                                )\n",
       "                                (lora_B): ModuleDict(\n",
       "                                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                                )\n",
       "                                (lora_embedding_A): ParameterDict()\n",
       "                                (lora_embedding_B): ParameterDict()\n",
       "                                (lora_magnitude_vector): ModuleDict()\n",
       "                              )\n",
       "                              (qkv_proj): lora.Linear4bit(\n",
       "                                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "                                (lora_dropout): ModuleDict(\n",
       "                                  (default): Dropout(p=0.05, inplace=False)\n",
       "                                )\n",
       "                                (lora_A): ModuleDict(\n",
       "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                                )\n",
       "                                (lora_B): ModuleDict(\n",
       "                                  (default): Linear(in_features=8, out_features=9216, bias=False)\n",
       "                                )\n",
       "                                (lora_embedding_A): ParameterDict()\n",
       "                                (lora_embedding_B): ParameterDict()\n",
       "                                (lora_magnitude_vector): ModuleDict()\n",
       "                              )\n",
       "                            )\n",
       "                            (mlp): Phi3MLP(\n",
       "                              (gate_up_proj): lora.Linear4bit(\n",
       "                                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "                                (lora_dropout): ModuleDict(\n",
       "                                  (default): Dropout(p=0.05, inplace=False)\n",
       "                                )\n",
       "                                (lora_A): ModuleDict(\n",
       "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                                )\n",
       "                                (lora_B): ModuleDict(\n",
       "                                  (default): Linear(in_features=8, out_features=16384, bias=False)\n",
       "                                )\n",
       "                                (lora_embedding_A): ParameterDict()\n",
       "                                (lora_embedding_B): ParameterDict()\n",
       "                                (lora_magnitude_vector): ModuleDict()\n",
       "                              )\n",
       "                              (down_proj): lora.Linear4bit(\n",
       "                                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                                (lora_dropout): ModuleDict(\n",
       "                                  (default): Dropout(p=0.05, inplace=False)\n",
       "                                )\n",
       "                                (lora_A): ModuleDict(\n",
       "                                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
       "                                )\n",
       "                                (lora_B): ModuleDict(\n",
       "                                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                                )\n",
       "                                (lora_embedding_A): ParameterDict()\n",
       "                                (lora_embedding_B): ParameterDict()\n",
       "                                (lora_magnitude_vector): ModuleDict()\n",
       "                              )\n",
       "                              (activation_fn): SiLU()\n",
       "                            )\n",
       "                            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "                            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "                            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "                        (rotary_emb): Phi3RotaryEmbedding()\n",
       "                      )\n",
       "                      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r = 8, #. rank of LoRA - [4-16]\n",
    "    bias = \"none\", # [\"all\", \"lora_only\"] - for train bias term\n",
    "    lora_alpha = 16, # scalling factor \n",
    "    lora_dropout = 0.05, # prevent overfit- used for regularisation\n",
    "    target_modules = [\"query_key_value\", \"o_proj\", \"qkv_proj\", \"gate_up_proj\", \"down_proj\"],\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Lxz8fPMuhX",
    "outputId": "1b513c00-cffe-4a68-8d65-8317b92d886a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2528.2619018554688\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDx5hjxXM6ZS",
    "outputId": "c8623789-bdb4-4186-d132-252da7d4e69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method PeftModel.get_base_model of PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PeftModelForCausalLM(\n",
      "      (base_model): LoraModel(\n",
      "        (model): PeftModelForCausalLM(\n",
      "          (base_model): LoraModel(\n",
      "            (model): PeftModelForCausalLM(\n",
      "              (base_model): LoraModel(\n",
      "                (model): PeftModelForCausalLM(\n",
      "                  (base_model): LoraModel(\n",
      "                    (model): Phi3ForCausalLM(\n",
      "                      (model): Phi3Model(\n",
      "                        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
      "                        (layers): ModuleList(\n",
      "                          (0-31): 32 x Phi3DecoderLayer(\n",
      "                            (self_attn): Phi3Attention(\n",
      "                              (o_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (qkv_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=9216, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                            )\n",
      "                            (mlp): Phi3MLP(\n",
      "                              (gate_up_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=16384, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (down_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (activation_fn): SiLU()\n",
      "                            )\n",
      "                            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "                            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "                            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "                            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "                          )\n",
      "                        )\n",
      "                        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "                        (rotary_emb): Phi3RotaryEmbedding()\n",
      "                      )\n",
      "                      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.get_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1xiTbhpNGYd",
    "outputId": "d9c58b8b-e715-4b6e-bd8e-e89ab22d3935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651.074752\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnvrkrmbNWnI",
    "outputId": "819c1a1a-63ec-4303-a373-be3d1ce84726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 12,582,912\n",
      "Total Parameters: 3,833,662,464\n",
      "Percentage Trainable: 0.33%\n"
     ]
    }
   ],
   "source": [
    "trainable_params, total_params = model.get_nb_trainable_parameters()\n",
    "percentage = (trainable_params / total_params) * 100\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Percentage Trainable: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different LoRA ranks and dropout rates\n",
    "for r in [4, 8, 16]: # for bigger dataset keep rank high and for smaller dataset keep rank low\n",
    "    for dropout in [0.01, 0.05, 0.1]: # for bigger dataset keep dropout low and for smaller dataset keep dropout high\n",
    "        config = LoraConfig(\n",
    "            r=r,\n",
    "            bias=\"none\",\n",
    "            lora_alpha=16,\n",
    "            lora_dropout=dropout,\n",
    "            target_modules=[\"query_key_value\", \"o_proj\", \"qkv_proj\", \"gate_up_proj\", \"down_proj\"],\n",
    "            task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "        temp_model = get_peft_model(model, config)\n",
    "        print(f\"LoRA rank: {r}, Dropout: {dropout}, Trainable params: {temp_model.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset from Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('imdb')  # You can change 'imdb' to any other public dataset\n",
    "print(dataset['train'][0])  # Print the first training example"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
